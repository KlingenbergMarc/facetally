{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: Pillow in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (10.1.0)\n",
            "Requirement already satisfied: filelock in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (3.13.1)\n",
            "Collecting huggingface-hub>=0.19.4 (from diffusers)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: importlib-metadata in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: numpy in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (1.26.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from diffusers) (2.31.0)\n",
            "Collecting safetensors>=0.3.1 (from diffusers)\n",
            "  Downloading safetensors-0.4.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->diffusers) (2023.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->diffusers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->diffusers) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->diffusers) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->diffusers) (2023.11.17)\n",
            "Downloading diffusers-0.24.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-macosx_10_7_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m737.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.24.0 huggingface-hub-0.19.4 safetensors-0.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install diffusers --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting invisible_watermark\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: safetensors in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (0.4.1)\n",
            "Requirement already satisfied: Pillow>=6.0.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from invisible_watermark) (10.1.0)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible_watermark)\n",
            "  Downloading pywavelets-1.5.0-cp310-cp310-macosx_10_13_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from invisible_watermark) (1.26.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from invisible_watermark) (4.8.1.78)\n",
            "Requirement already satisfied: torch in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from invisible_watermark) (2.1.1)\n",
            "Requirement already satisfied: filelock in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.0-cp310-cp310-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
            "Requirement already satisfied: sympy in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from torch->invisible_watermark) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from torch->invisible_watermark) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from torch->invisible_watermark) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from jinja2->torch->invisible_watermark) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages (from sympy->torch->invisible_watermark) (1.3.0)\n",
            "Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.5.0-cp310-cp310-macosx_10_13_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-macosx_10_7_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, tokenizers, invisible_watermark, accelerate, transformers\n",
            "Successfully installed PyWavelets-1.5.0 accelerate-0.25.0 invisible_watermark-0.2.0 tokenizers-0.15.0 transformers-4.35.2\n"
          ]
        }
      ],
      "source": [
        "! pip install invisible_watermark transformers accelerate safetensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gabriellemacaire/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2023-12-04 16:38:27.851387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model_index.json: 100%|██████████| 612/612 [00:00<00:00, 1.38MB/s]\n",
            "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]\n",
            "\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/tokenizer_config.json: 100%|██████████| 725/725 [00:00<00:00, 59.9kB/s]\n",
            "unet/config.json: 100%|██████████| 1.71k/1.71k [00:00<00:00, 151kB/s]\n",
            "tokenizer_2/special_tokens_map.json: 100%|██████████| 460/460 [00:00<00:00, 31.5kB/s]\n",
            "scheduler/scheduler_config.json: 100%|██████████| 479/479 [00:00<00:00, 21.8kB/s]\n",
            "text_encoder_2/config.json: 100%|██████████| 575/575 [00:00<00:00, 18.1kB/s]\n",
            "Fetching 13 files:  15%|█▌        | 2/13 [00:00<00:03,  2.84it/s]\n",
            "\u001b[A\n",
            "\n",
            "vae/config.json: 100%|██████████| 642/642 [00:00<00:00, 739kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 2.62MB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "tokenizer_2/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 941kB/s]\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "diffusion_pytorch_model.fp16.safetensors: 100%|██████████| 167M/167M [00:32<00:00, 5.22MB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100%|██████████| 167M/167M [01:46<00:00, 1.57MB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "model.fp16.safetensors: 100%|██████████| 1.39G/1.39G [06:02<00:00, 3.83MB/s]\n",
            "Fetching 13 files:  31%|███       | 4/13 [06:03<16:00, 106.74s/it]\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "diffusion_pytorch_model.fp16.safetensors: 100%|██████████| 4.52G/4.52G [11:39<00:00, 6.46MB/s]\n",
            "Fetching 13 files: 100%|██████████| 13/13 [11:41<00:00, 53.94s/it]\n",
            "Loading pipeline components...: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/gabriellemacaire/code/Projects/facetally/notebooks/Test-for-image-generation.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gabriellemacaire/code/Projects/facetally/notebooks/Test-for-image-generation.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabriellemacaire/code/Projects/facetally/notebooks/Test-for-image-generation.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabriellemacaire/code/Projects/facetally/notebooks/Test-for-image-generation.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m init_image \u001b[39m=\u001b[39m load_image(url)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:864\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    861\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been loaded in 8bit and moving it to \u001b[39m\u001b[39m{\u001b[39;00mtorch_dtype\u001b[39m}\u001b[39;00m\u001b[39m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    862\u001b[0m     )\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     module\u001b[39m.\u001b[39;49mto(device, dtype)\n\u001b[1;32m    866\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    867\u001b[0m     module\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mfloat16\n\u001b[1;32m    868\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mstr\u001b[39m(device) \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    869\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    870\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    871\u001b[0m ):\n\u001b[1;32m    872\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    873\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m     )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/torch/cuda/__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
            "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "pipe = pipe.to(\"cuda\")\n",
        "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
        "\n",
        "init_image = load_image(url).convert(\"RGB\")\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "image = pipe(prompt, image=init_image).images\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
