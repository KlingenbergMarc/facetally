{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is dedicated to face detection in images using YOLOv8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0IEVH3GhLnAT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 10:27:30.138932: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-04 10:27:30.139035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-04 10:27:30.246219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-04 10:27:30.447520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-04 10:27:32.609409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/klingenm/.pyenv/versions/3.10.6/envs/facetally/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras_cv import bounding_box\n",
        "from keras_cv import visualization\n",
        "import keras_cv\n",
        "from face_tally.params import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHkVGFK5QLhN"
      },
      "source": [
        "# Data Acquisition and Exploration\n",
        "\n",
        "Project Root and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_image_folder = os.path.join(LOCAL_DATA_PATH, 'image_data')\n",
        "path_annot = os.path.join(LOCAL_DATA_PATH, 'bbox_train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataframe Loading and Initial Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5733"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List all files and directories in the given path\n",
        "elements = os.listdir(test_image_folder)\n",
        "# Count the number of elements\n",
        "num_elements = len(elements)\n",
        "num_elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4lhnLJUUQRoR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>612</td>\n",
              "      <td>408</td>\n",
              "      <td>192</td>\n",
              "      <td>199</td>\n",
              "      <td>230</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>612</td>\n",
              "      <td>408</td>\n",
              "      <td>247</td>\n",
              "      <td>168</td>\n",
              "      <td>291</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>612</td>\n",
              "      <td>408</td>\n",
              "      <td>321</td>\n",
              "      <td>176</td>\n",
              "      <td>366</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>612</td>\n",
              "      <td>408</td>\n",
              "      <td>355</td>\n",
              "      <td>183</td>\n",
              "      <td>387</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10002.jpg</td>\n",
              "      <td>612</td>\n",
              "      <td>408</td>\n",
              "      <td>339</td>\n",
              "      <td>165</td>\n",
              "      <td>378</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Name  width  height  xmin  ymin  xmax  ymax\n",
              "0  10001.jpg    612     408   192   199   230   235\n",
              "1  10001.jpg    612     408   247   168   291   211\n",
              "2  10001.jpg    612     408   321   176   366   222\n",
              "3  10001.jpg    612     408   355   183   387   214\n",
              "4  10002.jpg    612     408   339   165   378   202"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(path_annot)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-wGpUmQdCA"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Preprocessing: Convert to REL_XYXY Format, https://keras.io/api/keras_cv/bounding_box/formats/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "35NFh66BqsAq",
        "outputId": "e1e08dbe-7101-4ff5-8852-50f27ac594a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>LEFT</th>\n",
              "      <th>TOP</th>\n",
              "      <th>RIGHT</th>\n",
              "      <th>BOTTOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>0.487745</td>\n",
              "      <td>0.375817</td>\n",
              "      <td>0.575980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>0.403595</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.475490</td>\n",
              "      <td>0.517157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>0.524510</td>\n",
              "      <td>0.431373</td>\n",
              "      <td>0.598039</td>\n",
              "      <td>0.544118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>0.580065</td>\n",
              "      <td>0.448529</td>\n",
              "      <td>0.632353</td>\n",
              "      <td>0.524510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10002.jpg</td>\n",
              "      <td>0.553922</td>\n",
              "      <td>0.404412</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.495098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Name      LEFT       TOP     RIGHT    BOTTOM\n",
              "0  10001.jpg  0.313725  0.487745  0.375817  0.575980\n",
              "1  10001.jpg  0.403595  0.411765  0.475490  0.517157\n",
              "2  10001.jpg  0.524510  0.431373  0.598039  0.544118\n",
              "3  10001.jpg  0.580065  0.448529  0.632353  0.524510\n",
              "4  10002.jpg  0.553922  0.404412  0.617647  0.495098"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to REL_XYXY format\n",
        "df['LEFT'] = df['xmin'] / df['width'] # LEFT: left of the bounding box\n",
        "df['TOP'] = df['ymin'] / df['height'] # TOP: top of the bounding box\n",
        "df['RIGHT'] = df['xmax'] / df['width'] # RIGHT: right of the bounding box\n",
        "df['BOTTOM'] = df['ymax'] / df['height'] # BOTTOM: bottom of the bounding box\n",
        "\n",
        "# Selecting only the required columns\n",
        "df_rel_xyxy = df[['Name', 'LEFT', 'TOP', 'RIGHT', 'BOTTOM']]\n",
        "\n",
        "#Now we have all columns in the correct format\n",
        "df_rel_xyxy.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aggregate Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MrXjjbPjtIfa",
        "outputId": "61f551f2-30c5-4624-e8cb-84bb4a3a6882"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>boxes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10001.jpg</td>\n",
              "      <td>[[0.3137254901960784, 0.4877450980392157, 0.37...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10002.jpg</td>\n",
              "      <td>[[0.553921568627451, 0.40441176470588236, 0.61...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10003.jpg</td>\n",
              "      <td>[[0.08823529411764706, 0.015665796344647518, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10004.jpg</td>\n",
              "      <td>[[0.22549019607843138, 0.4692874692874693, 0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10006.jpg</td>\n",
              "      <td>[[0.2875816993464052, 0.3897058823529412, 0.36...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Name                                              boxes\n",
              "0  10001.jpg  [[0.3137254901960784, 0.4877450980392157, 0.37...\n",
              "1  10002.jpg  [[0.553921568627451, 0.40441176470588236, 0.61...\n",
              "2  10003.jpg  [[0.08823529411764706, 0.015665796344647518, 0...\n",
              "3  10004.jpg  [[0.22549019607843138, 0.4692874692874693, 0.3...\n",
              "4  10006.jpg  [[0.2875816993464052, 0.3897058823529412, 0.36..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a function to aggregate bounding box coordinates for each image.\n",
        "def aggregate_boxes(data):\n",
        "    boxes = data[['LEFT', 'TOP', 'RIGHT', 'BOTTOM']].values.tolist()\n",
        "    return boxes\n",
        "\n",
        "# Apply the aggregate function to the grouped data and reset the index.\n",
        "grouped = df_rel_xyxy.groupby('Name').apply(aggregate_boxes).reset_index(name='boxes')\n",
        "grouped.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Paths and Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IOtFinyGtMEe"
      },
      "outputs": [],
      "source": [
        "image_paths = []\n",
        "bboxes = []\n",
        "\n",
        "# Iterate through the grouped dataframe and populate the lists with image paths and bounding boxes.\n",
        "for _, row in grouped.iterrows():\n",
        "    image_path = os.path.join(test_image_folder, row['Name'])\n",
        "    image_bboxes = row['boxes']\n",
        "    image_paths.append(image_path)\n",
        "    bboxes.append(image_bboxes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert to TensorFlow Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-9iIGDrY9tiP"
      },
      "outputs": [],
      "source": [
        "# Convert the lists to TensorFlow tensors. Use a ragged tensor for bounding boxes to handle varying lengths.\n",
        "bbox = tf.ragged.constant(bboxes, dtype=tf.float32)  # Bounding boxes\n",
        "classes = tf.ragged.constant([[0] * len(b) for b in bboxes], dtype=tf.int32)  # Class labels\n",
        "image_paths = tf.constant(image_paths)  # Image paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zkVCopU993W2"
      },
      "outputs": [],
      "source": [
        "# Function to load images without resizing, resize later\n",
        "def load_image(image_path):\n",
        "    # Read the image file and decode it to a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aag3m2p399N1"
      },
      "outputs": [],
      "source": [
        "# Function to create the data dictionary required by KerasCV without resizing the image\n",
        "def load_dataset(image_path, bbox, classes):\n",
        "    # Load the image\n",
        "    image = load_image(image_path)\n",
        "    # Create a dictionary for bounding boxes with 'boxes' and 'classes' as keys\n",
        "    bounding_boxes = {'boxes': bbox, 'classes': classes}\n",
        "    # Return a dictionary with 'images' and 'bounding_boxes'\n",
        "    return {'images': image, 'bounding_boxes': bounding_boxes}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UyTa4Gf09_rh"
      },
      "outputs": [],
      "source": [
        "# Create a tf.data.Dataset that combines the image paths with bounding boxes and class labels\n",
        "data = tf.data.Dataset.from_tensor_slices((image_paths, bbox, classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NT1umpYX-UTU"
      },
      "outputs": [],
      "source": [
        "augmenter = keras.Sequential(\n",
        "    layers=[\n",
        "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"rel_xyxy\"),\n",
        "        keras_cv.layers.RandomShear(\n",
        "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"rel_xyxy\"\n",
        "        ),\n",
        "        keras_cv.layers.JitteredResize(\n",
        "            target_size=(640, 640), scale_factor=(0.75, 1.3), bounding_box_format=\"rel_xyxy\"\n",
        "        ),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_0yi8-WUFqqs"
      },
      "outputs": [],
      "source": [
        "all_images_len = len(set(df.Name))\n",
        "\n",
        "train_idx = int(all_images_len * 0.8)\n",
        "validation_idx = int(all_images_len* 0.15)\n",
        "# test_idx = int(all_images_len- train_idx - validation_idx)\n",
        "\n",
        "train_data = data.take(train_idx)\n",
        "val_data = data.skip(train_idx).take(validation_idx)\n",
        "# test_data = data.skip(train_idx + validation_idx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-vztm6wCIQJq"
      },
      "outputs": [],
      "source": [
        "SPLIT_RATIO = 0.2\n",
        "BATCH_SIZE = 4\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCH = 5\n",
        "GLOBAL_CLIPNORM = 10.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1_uZebSSICCO"
      },
      "outputs": [],
      "source": [
        "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
        "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pbOgjCmHIUHK"
      },
      "outputs": [],
      "source": [
        "resizing = keras_cv.layers.JitteredResize(\n",
        "    target_size=(640, 640),\n",
        "    scale_factor=(0.75, 1.3),\n",
        "    bounding_box_format=\"rel_xyxy\",\n",
        ")\n",
        "\n",
        "val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.shuffle(BATCH_SIZE * 4)\n",
        "val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Class IDs and Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UFTjFj-uJAE_"
      },
      "outputs": [],
      "source": [
        "# Define the class ids and mapping. In this case, we have only one class 'face'.\n",
        "class_ids = [\"face\"]\n",
        "class_mapping = {0: \"face\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PDlE9dt-IeG9",
        "outputId": "87543255-e2bb-401a-c2f7-b27c9b2fd930"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
        "    inputs = next(iter(inputs.take(1)))\n",
        "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
        "    visualization.plot_bounding_box_gallery(\n",
        "        images,\n",
        "        value_range=value_range,\n",
        "        rows=rows,\n",
        "        cols=cols,\n",
        "        y_true=bounding_boxes,\n",
        "        scale=5,\n",
        "        font_scale=0.7,\n",
        "        bounding_box_format=bounding_box_format,\n",
        "        class_mapping=class_mapping,\n",
        "    )\n",
        "\n",
        "\n",
        "visualize_dataset(\n",
        "    train_ds, bounding_box_format=\"rel_xyxy\", value_range=(0, 255), rows=2, cols=2\n",
        ")\n",
        "\n",
        "visualize_dataset(\n",
        "    val_ds, bounding_box_format=\"rel_xyxy\", value_range=(0, 255), rows=2, cols=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dictionary to Tuple Conversion for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R722BaPwIzIh"
      },
      "outputs": [],
      "source": [
        "def dict_to_tuple(inputs):\n",
        "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
